{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: Conceptos básicos de Tensorflow\n",
    "En este tutorial veremos algunos conceptos importantes para poder comenzar a utilizar tensorflow para tareas de deep learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensores\n",
    "Un **tensor** es un arreglo multidimensional con elementos del mismo tipo (dtype). En escencia, un tensor de tensorflow es muy similar en comportamiento a un array de numpy con algunas diferencias y funcionalidades agregadas.\n",
    "Por definición, todos los tensores son *inmutables*, es decir que no se puede actualizar el contenido de uno, solamente crear uno nuevo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operaciones básicas\n",
    "Veremos como crear y definir tensores usando tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# crear un tensor de rango 0, un escalar, no contiene ejes\n",
    "simple_tensor = tf.constant(4)\n",
    "print(simple_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# un tensor de rango 1 es similar a una lista de valores, tiene un eje\n",
    "r1_tensor = tf.constant([2.0,3.0,4.0,5.0])\n",
    "print(r1_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# un tensor de rango 2 es una matriz\n",
    "r2_tensor = tf.constant([[2.0,3.0,4.0,5.0],[1.0,2.0,0.0,1.0]])\n",
    "print(r2_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# un tensor puede tener un numero arbitrario de ejes o dimensiones\n",
    "rank_3_tensor = tf.constant([\n",
    "  [[0, 1.0, 2, 3, 4],\n",
    "   [5, 6, 7, 8, 9]],\n",
    "  [[10, 11, 12, 13, 14],\n",
    "   [15, 16, 17, 18, 19]],\n",
    "  [[20, 21, 22, 23, 24],\n",
    "   [25, 26, 27, 28, 29]],], dtype=tf.float16)\n",
    "                    \n",
    "print(rank_3_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay varias formas de visualizar un tensor de más de 2 dimensiones\n",
    "![tensor](img/3atensor.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# se puede convertir un tensor a un array de numpy de varias maneras:\n",
    "M = np.array(r2_tensor)\n",
    "M2 = r2_tensor.numpy()\n",
    "print(type(M))\n",
    "print(type(M2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# se pueden realizar operaciones basicas con tensores como adicion, multiplicacion y multiplicacion de matrices\n",
    "a = tf.constant([[1, 2],\n",
    "                 [3, 4]])\n",
    "b = tf.constant([[1, 1],\n",
    "                 [1, 1]]) # tambien se puede usar `tf.ones([2,2])`\n",
    "\n",
    "print(tf.add(a, b), \"\\n\")\n",
    "print(tf.multiply(a, b), \"\\n\")\n",
    "print(tf.matmul(a, b), \"\\n\")\n",
    "print('numpy:',np.dot(a.numpy(), b.numpy()))\n",
    "print(a + b, \"\\n\") # element-wise addition\n",
    "print(a * b, \"\\n\") # element-wise multiplication\n",
    "print(a @ b, \"\\n\") # matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# se pueden usar tensores en todo tipo de operaciones adicionales\n",
    "c = tf.constant([[4.0, 5.0], [10.0, 1.0]])\n",
    "\n",
    "# valor maximo\n",
    "print(tf.reduce_max(c))\n",
    "# indice del valor maximo\n",
    "print(tf.argmax(c))\n",
    "# calcular la funcion softmax\n",
    "print(tf.nn.softmax(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se tienen alguas definiciones importantes (similares a numpy):\n",
    "\n",
    "  - **shape** es el tamaño (numero de elementos) de cada dimension de un tensor.\n",
    "  - **rank** es el numero de dimensiones del tensor, un escalar tiene rank 0, una matriz rank 2\n",
    "  - **axis** o **dimension** es una dimensión en particular de un tensor.\n",
    "  - **size** el numero total de elementos de un tensor, el producto del vector *shape*.\n",
    "  \n",
    "Podemos visualizar para un tensor de rank 4\n",
    "\n",
    "\n",
    "![r4](img/4atensor.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rank_4_tensor = tf.zeros([3, 2, 4, 5])\n",
    "\n",
    "print(\"Tipo de cada elemento:\", rank_4_tensor.dtype)\n",
    "print(\"Numero de dimensiones:\", rank_4_tensor.ndim)\n",
    "print(\"Shape:\", rank_4_tensor.shape)\n",
    "print(\"Elementos en el eje 0 del tensor:\", rank_4_tensor.shape[0])\n",
    "print(\"Elementos en el ultimo eje del tensor:\", rank_4_tensor.shape[-1])\n",
    "print(\"Numero total de elementos (3*2*4*5): \", tf.size(rank_4_tensor).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rank_1_tensor = tf.constant([0, 1, 1, 2, 3, 5, 8, 13, 21, 34])\n",
    "# indexado con un escalar\n",
    "print(rank_1_tensor.numpy())\n",
    "print(\"First:\", rank_1_tensor[0].numpy())\n",
    "print(\"Second:\", rank_1_tensor[1].numpy())\n",
    "print(\"Last:\", rank_1_tensor[-1].numpy())\n",
    "# indexado con un slice\n",
    "print(\"Everything:\", rank_1_tensor[:].numpy())\n",
    "print(\"Before 4:\", rank_1_tensor[:4].numpy())\n",
    "print(\"From 4 to the end:\", rank_1_tensor[4:].numpy())\n",
    "print(\"From 2, before 7:\", rank_1_tensor[2:7].numpy())\n",
    "print(\"Every other item:\", rank_1_tensor[::2].numpy())\n",
    "print(\"Reversed:\", rank_1_tensor[::-1].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rank_2_tensor = tf.constant([[1, 2],\n",
    "                             [3, 4],\n",
    "                             [5, 6]], dtype=tf.float16)\n",
    "print(rank_2_tensor.numpy())\n",
    "                            \n",
    "# pasando un entero por cada dimension, arroja un escalar\n",
    "print(rank_2_tensor[1, 1].numpy())\n",
    "\n",
    "# Se puede indexar usando combinaciones de escalares y slices\n",
    "print(\"Second row:\", rank_2_tensor[1, :].numpy())\n",
    "print(\"Second column:\", rank_2_tensor[:, 1].numpy())\n",
    "print(\"Last row:\", rank_2_tensor[-1, :].numpy())\n",
    "print(\"First item in last column:\", rank_2_tensor[0, -1].numpy())\n",
    "print(\"Skip the first row:\")\n",
    "print(rank_2_tensor[1:, :].numpy(), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ejemplo de un tensor de 3 dimensiones\n",
    "print(rank_3_tensor[:, :, 4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![3slice](img/3rslice.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables\n",
    "Una variable de tensorflow es una forma de representar algun estado persistente que se puede manipular por un programa.\n",
    "Las variables son manipuladas a traves de la clase 'tf.variable'. Una variable de tensorflow representa un **tensor** cuyo valor puede cambiar mediante la ejecución de **operaciones** sobre la misma. Las operaciones u **ops** permiten leer y modificar los valores de un tensor. \n",
    "\n",
    "Usualmente las variables de tensorflow se usan para almacenar los pesos del modelo de red neuronal.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# para crear una variable \n",
    "mi_variable = tf.Variable(tf.zeros([1, 2, 3]))\n",
    "print(mi_variable)\n",
    "# para usar una variable simplemente se puede operar como si fuera un tensor normal\n",
    "v = tf.Variable(0.0)\n",
    "w = v + 1 \n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# se puede asignar un nuevo valor o incrementar una variable\n",
    "v = tf.Variable(3.1)\n",
    "print(v)\n",
    "v.assign(1.0)\n",
    "print(v)\n",
    "v.assign_add(1)\n",
    "v.assign_add(2)\n",
    "\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cálculo automático de gradientes\n",
    "\n",
    "Para poder usar la capacidad de diferenciación automática de tensorflow, se necesita recordar todas las operaciones que han ocurrido y el orden de ocurrencia durante el *forward pass*. Luego, durante el *backward pass*, tensorflow puede recorrer la lista de operaciones y calcular las grandientes.\n",
    "\n",
    "### Gradient tapes\n",
    "Tensorflow provee la API de **tf.GradientTape** para la diferenciación automática y poder calcular las gradientes de un grafo de cómputo con respecto a ciertas variables de entrada. Tensorflow \"recuerda\" todas las operaciones ejecutadas dentro el contexto de **tf.GradienTape** en un *tape*. Luego, se usa ese tape y las gradientes asociadas con cada operacion para calcular las gradientes restantes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.constant(3.0)\n",
    "# y = x ^ 2\n",
    "with tf.GradientTape() as t:\n",
    "  t.watch(x)        # para grabar las operacioens sobre x\n",
    "  y = x * x\n",
    "# dy = 2x\n",
    "dy_dx = t.gradient(y, x)\n",
    "dy_dx.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = tf.constant([3.0, 3.0])\n",
    "\n",
    "with tf.GradientTape() as t:\n",
    "  t.watch(x)\n",
    "  z = tf.multiply(x, x)\n",
    "\n",
    "print(z)\n",
    "\n",
    "# Find derivative of z with respect to the original input tensor x\n",
    "print(t.gradient(z, x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es importante usar siempre tensores dentro de las operaciones del tape para garantizar el calculo de gradientes adecuado. Si se tiene un valor fijo, primero se debe convertirlo a un tensor con tf.constant antes de usarlo en el flujo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tambien se puede solicitar gradientes de la salida con respecto a valores intermedios calculados durante una \"grabación\" de un contexto tf.GradientTape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = tf.constant([3.0, 3.0])\n",
    "\n",
    "with tf.GradientTape() as t:\n",
    "  t.watch(x)\n",
    "  y = tf.multiply(x, x)\n",
    "  z = tf.multiply(y, y)\n",
    "\n",
    "# Se usa el tape para calcular la derivada de z con respecto al valor intermedio y\n",
    "# dz_dx = 2 * y, donde: y = x ^ 2\n",
    "print(t.gradient(z, y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = tf.Variable(2.0)\n",
    "y = tf.Variable(3.0)\n",
    "\n",
    "with tf.GradientTape() as t:\n",
    "  # No hay necesidad de invocar watch\n",
    "  y_sq = y * y\n",
    "  z = x + y_sq\n",
    "\n",
    "print(t.watched_variables())\n",
    "print(t.gradient(z,y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresion lineal en tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "import random\n",
    "# X y y ya son arrays de numpy\n",
    "X, y = load_diabetes(return_X_y=True)\n",
    "\n",
    "m = X.shape[0]\n",
    "unos = np.ones((m, 1))\n",
    "X = np.append(unos, X, axis=1)\n",
    "\n",
    "X = tf.constant(X, dtype=tf.float32)\n",
    "y = tf.constant(y, dtype=tf.float32)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n = 20\n",
    "alpha = tf.constant(0.001, dtype=tf.float32)\n",
    "theta = tf.Variable(tf.random.uniform([X.shape[1], 1], minval=-1, maxval=1), dtype=tf.float32)\n",
    "# print(theta.shape, theta)\n",
    "cost_history = []\n",
    "z = tf.matmul(X, theta)\n",
    "cost_history.append((1/(2 * m)) * tf.math.reduce_sum(tf.square(z - y)))\n",
    "print(f'costo inicial: {cost_history[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# entrenamiento usando gradient tape\n",
    "for _ in range(n):\n",
    "    #forward pass\n",
    "    with tf.GradientTape() as t:\n",
    "        t.watch(theta)\n",
    "        ## regresion lineal\n",
    "        z = tf.matmul(X, theta)\n",
    "        # costo\n",
    "        # (1/(2*m))*np.sum(np.square(hyp(x, w, b) - y))\n",
    "        J = (1/(2 * m)) * tf.math.reduce_sum(tf.square(z - y))\n",
    "        cost_history.append(J)\n",
    "\n",
    "    dtheta = t.gradient(J, theta)\n",
    "    # print(f'dtheta: {dtheta}')\n",
    "    theta = theta - dtheta * alpha\n",
    "\n",
    "print('terminado')\n",
    "print(f'costo inicial: {cost_history[0]}\\ncosto final: {cost_history[-1]}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "it = list(range(n + 1))\n",
    "plt.plot(it, cost_history)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}